# 7 Observability with Istio: understanding the behavior of your services

DevOps나 SRE에서 핵심적으로 다룰 정도로 운영 측면에서 Observability는 상당히 중요해졌다.
운영 중인 서비스에서 어떤 일이 일어나고 있는지 살펴보고, 장애 상황을 빠르게 인지하고 복구하거나 개선시켜 나가므로써 결국 서비스의 품질을 향상시킬 수 있다.
하지만 마이크로 서비스에서는 하드웨어 서버가 아닌 더 작은 단위의 인스턴스들로 구성되어 있으며, 관리해야할 대상은 작게는 수십, 많게는 수천, 수만이 될지도 모른다.
이러한 상황에서 Obserbavility를 확보하는 것 자체도 굉장히 어려운 것인데, Istio가 Obserbavility를 위해 어떤 magic을 부렸는지 살펴보자.


### 7.1.1  Observability vs Monitoring
Monitoring은 Obervability의 subset이다. 
metric들을 모아 aggregating해서 어떤 treshold를 넘기면 alert을 보내는 데 이것이 바로 Monitoring 이라고 볼 수 있다. 

만약 어떤 유저에게 느린 응답을 내려갔을 때, 에러가 발생한 것도 아니고 alert이 걸려있지 않았다면 관리자는 인지할 수 없을 것이다.
하지만 obsavability를 고려해서 디자인을 한다면 service latency, intrastructure hops 같은 메트릭을 수집하고, 이러한 데이터를 통해서 에러가 아니더라도 서비스에 개선에 필요한 포인트들을 가시화할 수 있게된다.


### 7.1.2  How Istio helps with observability
Istio는 Obserbavility를 위해서 좋은 위치를 선점하고 있다. 바로 Sidecar proxy인 Envoy에서 서비스로 들어오는 혹은 나가는 트래픽을 처리할때 발생하는 여러 메트릭들을 애플리케이션 대신에 모을 수 있다. Prometheus나 Grafana에서 확인할 수 있는 모니터링에 필요한 기본적인 latency나 error count 뿐 아니라, OpenTracing 지원을 통해서 distributed tracing 데이터도 생성할 수 있으며 Jeager나 Zipkin을 통해서 확인이 가능하다.


## 7.2  Collecting metrics from Istio data plane
이 책의 소스는 (여기|https://github.com/istioinaction/book-source-code)에 있는 것을 사용하며, 7장(Observability) 내용을 실습하기 위해서는 `work-on-chapter06` 브랜치로 switch 해야한다.

아래 명령을 통해서 `catalog` 라는 서비스를 배포한다.
여기에는 `catalog`라는 서비스(혹은 애플리케이션) 자체 뿐 아니라, kubernetes의 `service, deployment`, istio의 `gateway, virtual service` 와 같은 리소스의 생성도 포함되어 있다.
```bash
make deploy-apigateway-with-catalog
```

이제 아래 명령을 통해서 서비스에 접근해서 정상적으로 실행되는지 살펴보자.
(참고로 ingress에 접근하기 위한 url을 뽑아오는 것도 makefile에 포함되어 있음)
```bash
curl  -H "Host: apigateway.istioinaction.io"  $(make ingress-url)/api/products
```

apigateway로 들어오는 incoming traffic과 관련된 통계 정보들을 살펴보면 
```bash
 kubectl exec -it $(make apigateway-pod) -c istio-proxy -- curl localhost:15000/stats | grep cluster.local | grep 8080
```
이 서비스에서 3개의 request가 성공했으며 2xx, 200을 리턴했다고 나오며, 아래와 같은 메트릭들을 StatsD와 같은 metric-collection system에 연동할 수 있다. 
```
apigateway.istioinaction.svc.cluster.local.internal.upstream_rq_200: 3
apigateway.istioinaction.svc.cluster.local.internal.upstream_rq_2xx: 3
apigateway.istioinaction.svc.cluster.local.internal.upstream_rq_completed: 3
...
```


### 7.2.1  Pushing Istio metrics into statsD

metric을 전송하기 위해서 StatsD를 setup해야한다. 
```bash
kubectl apply -f chapters/chapter7/statsd
```

StatsD 컨테이너로 들어가서 메트릭을 조회해보자.
```bash
kubectl exec -it pod_name_of_statsd sh
/app/statsd # echo "counters" | nc 127.0.0.1 8126
```

Istio가 StatsD 서버로 메트릭을 전송할 수 있게 deployment를 수정해보자.
아래는 in-place로 kubernetes 스펙을 수정할 수 있는 명령인 `kubectl edit`을 사용했으며 이때 Editor로 `vim`을 사용하였다.
```bash
KUBE_EDITOR="vim" kubectl edit deploy apigateway
```

수정해야할 부분은 apigateway의 sidecar proxy 컨테이너를 설정하는 부분의 실행 옵션에 `--statsdUdpAddress`를 추가하는 것이다.
```yaml
- args:
    - proxy
    - sidecar
    - --statsdUdpAddress
    - statsd:8125
```

이제 apigateway pod에 대한 Obserbavility가 확보되었다.
위에서 실행했던 StatsD의 메트릭을 조회하는 명령을 다시 실행해보면, envoy에서 전송된 메트릭들이 추가된 것을 확인할 수 있을 것이다.
```bash
kubectl exec -it pod_name_of_statsd sh
/app/statsd # echo "counters" | nc 127.0.0.1 8126
```

이번에는 모든 sidecar proxy가 우리가 생성한 StatsD로 metric을 전송하게 해보자.
Istio에서 sidecar proxy를 주입시켜줄때 참조하는 스펙을 변경하는 것이다.
위에서 했던것처럼 `--statsdUdpAddress` parameter를 추가하면된다. 
```bash
KUBE_EDITOR="vim" kubectl edit cm/istio-sidecar-injector -n istio-system
```

### 7.2.2  Pulling Istio Metrics into Prometheus
이제 Prometheus로 메트릭을 collect해보자. 위에서의 메트릭을 StatsD로 전송을 해야했지만, Prometheus는 기본적으로 metric의 endpoint로부터 pulling하기 때문에 조금 다른 설정이 필요하다.

기본적으로 Prometheus에서 pulling할 endpoint(localhost:15090/stats/prometheus)를 제공해주며, 이 endpoint를 통해서 수집되는 metric을 살펴보자.
```bash
kubectl exec -it pod_name_of_apigateway curl localhost:15090/stats/prometheus
```

Prometheus에서는 이러한 metric을 scrap하도록 설정만 하면 된다.
```yaml
# prometheus.yaml

global:
  scrape_interval: 15s
scrape_configs:

# Scrape config for envoy stats
- job_name: 'envoy-stats'
  metrics_path: /stats/prometheus	# scrape할 path
  kubernetes_sd_configs:			# kubernetes API

...

relabel_configs:
  - source_labels: [__meta_kubernetes_pod_container_port_name]
    action: keep
    regex: '.*-envoy-prom'			# prometheus port를 찾는다
```

그리고 이러한 설정 파일(prometheus.yaml)의 경우는 kuberntes의 ConfigMap로 설정하고 해당 pod에서 volume mount하는 방식으로 사용할 수 있다.
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    source: istioinaction
  name: istioinaction-prom
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
    scrape_configs:

    # Scrape config for envoy stats
    - job_name: 'envoy-stats'
      metrics_path: /stats/prometheus
      kubernetes_sd_configs:
      - role: pod

      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_container_port_name]
        action: keep
        regex: '.*-envoy-prom'
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:15090
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod_name
```
```bash
kubectl create -f chapters/chapter7/prom/prometheus-configmap.yaml
```

Prometheus의 Deployement에서 configMap을 volume mount로 사용할 수 있으며, Prometheus 실행시 parameter로 이 설정 파일을 명시해준다.
```yaml
apiVersion: extensions/v1beta1
kind: Deployment
...
  template:
  ...
    spec:
      containers:
      - args:
        - --storage.tsdb.retention=6h
        - --config.file=/etc/prometheus/prometheus.yml
        image: docker.io/prom/prometheus:v2.3.1
        imagePullPolicy: IfNotPresent
        ...
        volumeMounts:
        - mountPath: /etc/prometheus
          name: config-volume
      ...
      serviceAccount: prometheus
      serviceAccountName: prometheus
      volumes:
      - configMap:
          name: istioinaction-prom
        name: config-volume

```

Prometheus configuration을 생성했으니, deployment도 생성해보자.
```bash
kubectl create -f chapters/chapter7/prom/prometheus-deployment.yaml
```


이제 새로운 prometheus 서버로 쿼리해보자. 테스트를 위해 local환경에서 Prometheus에 접근하기 위해서 port-forward를 실행해보자.
```bash
kubectl port-forward pod_name_of_prometheus 9090:9090
```
이제 http://localhost:9090/graph 에 접속해 볼 수 있다.



## 7.3  Creating new metrics to send to Prometheus through Istio-telemetry
새로운 metric을 추가하기 위해서는 Istio에서 제공하는 `metric` 이라는 spec을 설정해야 한다.






